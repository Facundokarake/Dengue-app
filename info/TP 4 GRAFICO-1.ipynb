{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"48CdxvvL9P4l","outputId":"bfed67ee-760f-428c-963b-99700a4cc9e7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["\n","# === Montaje de Google Drive ===\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# === Ruta base en Drive (aj√∫stala si es necesario) ===\n","BASE_DIR = \"/content/drive/MyDrive/Facultad/Ciencia de datos/dengue_ckan/AirFlow/include/outputs/\"\n","\n","\n","# === Librer√≠as ===\n","import os\n","import sys\n","import math\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import re\n","from pandas.api.types import is_numeric_dtype\n","import matplotlib as mpl\n","import seaborn as sns\n","\n","\n","file_path = os.path.join(BASE_DIR, 'dengue_enriched_final.xlsx') # O .xlsx, etc.\n","df = pd.read_excel(file_path)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Df-ibZen9Sj8"},"outputs":[],"source":["# =========================\n","# PREPROCESAMIENTO DENGUE\n","# =========================\n","\n","\n","# 1) Resetear a defaults razonables\n","sns.reset_defaults()                 # resetea seaborn\n","mpl.rcParams.update(mpl.rcParamsDefault)  # resetea matplotlib\n","\n","# -------- utilidades --------\n","def normalize_text(s: str):\n","    if pd.isna(s): return s\n","    s = str(s).strip()\n","    s = (s\n","         .replace(\"√É‚Äò\", \"√ë\")\n","         .replace(\"√°\",\"a\").replace(\"√©\",\"e\").replace(\"√≠\",\"i\").replace(\"√≥\",\"o\").replace(\"√∫\",\"u\")\n","         .replace(\"√Å\",\"A\").replace(\"√â\",\"E\").replace(\"√ç\",\"I\").replace(\"√ì\",\"O\").replace(\"√ö\",\"U\")\n","         )\n","    s = re.sub(r'\\s+', ' ', s)\n","    return s.upper()\n","\n","def coerce_numeric(x, allow_comma_decimal=True):\n","    if pd.isna(x): return np.nan\n","    s = str(x).strip()\n","    if allow_comma_decimal and (',' in s) and ('.' not in s):\n","        s = s.replace('.', '')       # separador de miles\n","        s = s.replace(',', '.')      # coma decimal -\u003e punto\n","    # quitar posibles miles residuales 1.234 -\u003e 1234 si aplica\n","    s = re.sub(r'(?\u003c=\\d)\\.(?=\\d{3}\\b)', '', s)\n","    try:\n","        return float(s)\n","    except:\n","        return np.nan\n","\n","def fix_prov_name(p):\n","    p = normalize_text(p)\n","    if p in {\"CABA\",\"CIUDAD AUTONOMA BUENOS AIRES\",\"CAPITAL FEDERAL\"}:\n","        return \"CIUDAD AUTONOMA DE BUENOS AIRES\"\n","    return p\n","\n","def standardize_departamento(dep, prov=None):\n","    dep = normalize_text(dep) if pd.notna(dep) else dep\n","    prov = fix_prov_name(prov) if pd.notna(prov) else prov\n","    if prov == \"CIUDAD AUTONOMA DE BUENOS AIRES\" and isinstance(dep, str):\n","        m = re.search(r'COMUNA\\s*(\\d+)', dep)\n","        if m:\n","            return f\"COMUNA {int(m.group(1))}\"\n","    return dep\n","\n","# -------- 1) Normalizaci√≥n b√°sica de texto y tipos --------\n","display(df.head())\n","if \"provincia_nombre\" in df.columns:\n","    df[\"provincia_nombre\"] = df[\"provincia_nombre\"].apply(fix_prov_name)\n","if \"departamento_nombre\" in df.columns:\n","    df[\"departamento_nombre\"] = df.apply(\n","        lambda r: standardize_departamento(r.get(\"departamento_nombre\"), r.get(\"provincia_nombre\")), axis=1\n","    )\n","\n","# Fuerzo num√©ricos en potenciales columnas clim√°ticas/geo-demogr√°ficas\n","maybe_numeric = [c for c in df.columns if any(k in c.lower() for k in [\"lat\",\"lon\",\"temp\",\"hum\",\"prec\",\"poblacion\",\"densidad\",\"superficie\"])]\n","for c in maybe_numeric:\n","    if c in df.columns and df[c].dtype == \"O\":\n","        df[c] = df[c].apply(coerce_numeric)\n","\n","# # -------- 3) Columna de casos (asegurar existencia y tipo) --------\n","candidate_case_cols = [\"cantidad_casos\",\"casos\",\"n_casos\",\"count_casos\"]\n","case_col = next((c for c in candidate_case_cols if c in df.columns), None)\n","if case_col is None:\n","    raise ValueError(\"No se detect√≥ columna de casos (esperaba una de: cantidad_casos/casos/n_casos/count_casos).\")\n","if df[case_col].dtype == \"O\":\n","    df[case_col] = pd.to_numeric(df[case_col].apply(coerce_numeric), errors=\"coerce\")\n","df[case_col] = df[case_col].fillna(0).clip(lower=0)\n","\n","# -------- 4) Estandarizaci√≥n robusta de grupo_edad_desc + ID (sin nulos) --------\n","import re\n","\n","# Bandas can√≥nicas\n","_BANDS = [\n","    (0, 0,  \"0 a 0\"),\n","    (1, 4,  \"1 a 4\"),\n","    (5, 9,  \"5 a 9\"),\n","    (10,14, \"10 a 14\"),\n","    (15,19, \"15 a 19\"),\n","    (20,24, \"20 a 24\"),\n","    (25,34, \"25 a 34\"),\n","    (35,44, \"35 a 44\"),\n","    (45,64, \"45 a 64\"),\n","    (65,200,\"65+\"),\n","]\n","\n","def _age_to_band_inclusive(min_age: int, max_age: int) -\u003e str | None:\n","    \"\"\"Devuelve la banda que contiene [min,max]; si cruza, None.\"\"\"\n","    if max_age \u003e= 65:\n","        return \"65+\"\n","    for a, b, label in _BANDS:\n","        if a \u003c= min_age and max_age \u003c= b:\n","            return label\n","    return None\n","\n","def _age_single_band(age: int) -\u003e str:\n","    \"\"\"Banda que contiene una edad puntual.\"\"\"\n","    if age \u003e= 65:\n","        return \"65+\"\n","    for a, b, label in _BANDS:\n","        if a \u003c= age \u003c= b:\n","            return label\n","    return \"DESCONOCIDO\"\n","\n","def _normalize_text_edades(s):\n","    if pd.isna(s): return None\n","    s = str(s).strip().lower()\n","    s = (s.replace(\"√°\",\"a\").replace(\"√©\",\"e\").replace(\"√≠\",\"i\")\n","           .replace(\"√≥\",\"o\").replace(\"√∫\",\"u\").replace(\"√±\",\"n\"))\n","    s = re.sub(r\"\\s+\", \" \", s)\n","    return s\n","\n","def standardize_grupo_edad(desc) -\u003e str:\n","    \"\"\"\n","    Siempre devuelve una etiqueta can√≥nica: '0 a 0', '1 a 4', ..., '65+' o 'DESCONOCIDO'.\n","    Pol√≠tica cuando cruza bandas: usar la BANDA DEL M√ÅXIMO (conservadora).\n","    \"\"\"\n","    s = _normalize_text_edades(desc)\n","    if s is None or s in {\"\", \"sin especificar\", \"sin esp\"}:\n","        return \"DESCONOCIDO\"\n","\n","    # N√∫mero puro -\u003e banda\n","    if re.fullmatch(r\"\\d{1,3}\", s):\n","        return _age_single_band(int(s))\n","\n","    # Casos especiales\n","    if \"neonato\" in s or \"posneonato\" in s or (\"menor\" in s and \"1\" in s):\n","        return \"0 a 0\"\n","    if \"igual a 1\" in s:\n","        return \"1 a 4\"  # unificamos a la banda can√≥nica\n","\n","    # Rangos \"de X a Y\" / \"X a Y\" / \"X hasta Y\"\n","    m = re.search(r\"(\\d+)\\s*(?:de\\s+)?(?:a|hasta)\\s*(\\d+)\", s)\n","    if m:\n","        x, y = int(m.group(1)), int(m.group(2))\n","        lo, hi = (x, y) if x \u003c= y else (y, x)\n","        lab = _age_to_band_inclusive(lo, hi)\n","        if lab:\n","            return lab\n","        # Cruza bandas -\u003e usar banda del m√°ximo (conservadora)\n","        return _age_single_band(hi)\n","\n","    # 65+ variantes\n","    if (\"mayor\" in s and \"65\" in s) or \"65 y mas\" in s or \"65+\" in s:\n","        return \"65+\"\n","\n","    # Varios n√∫meros sueltos (p.ej., \"1 2 3 4 5 7\")\n","    nums = [int(n) for n in re.findall(r\"\\d+\", s)]\n","    if len(nums) \u003e= 1:\n","        # Pol√≠tica: usar banda del m√°ximo\n","        return _age_single_band(max(nums))\n","\n","    return \"DESCONOCIDO\"\n","\n","# Aplicar al DF\n","if \"grupo_edad_desc\" in df.columns:\n","    df[\"grupo_edad_desc_std\"] = df[\"grupo_edad_desc\"].apply(standardize_grupo_edad)\n","else:\n","    df[\"grupo_edad_desc_std\"] = \"DESCONOCIDO\"\n","\n","# Mapeo a ID (incluye DESCONOCIDO=99 para evitar nulos)\n","ID_MAP = {\n","    \"0 a 0\": 0,\n","    \"1 a 4\": 1,\n","    \"5 a 9\": 2,\n","    \"10 a 14\": 3,\n","    \"15 a 19\": 4,\n","    \"20 a 24\": 5,\n","    \"25 a 34\": 6,\n","    \"35 a 44\": 7,\n","    \"45 a 64\": 8,\n","    \"65+\": 9,\n","    \"DESCONOCIDO\": 99\n","}\n","df[\"grupo_edad_id\"] = df[\"grupo_edad_desc_std\"].map(ID_MAP).astype(\"Int64\")\n","\n","\n","# -------- 5) Completar IDs de provincia y departamento --------\n","def completar_id_por_modo(df, nombre_col, id_col, adicionales_keys=None):\n","    if nombre_col not in df.columns or id_col not in df.columns:\n","        return df\n","    d = df.copy()\n","    # Mapa nombre -\u003e id m√°s frecuente observado\n","    mapa = (d[[nombre_col, id_col]]\n","            .dropna()\n","            .groupby(nombre_col)[id_col]\n","            .agg(lambda s: s.value_counts().idxmax())\n","            .to_dict())\n","    # Completar faltantes\n","    mask = d[id_col].isna() \u0026 d[nombre_col].notna()\n","    d.loc[mask, id_col] = d.loc[mask, nombre_col].map(mapa)\n","\n","    # (opcional) completar con c√≥digos deterministas si a√∫n faltan\n","    if d[id_col].isna().any():\n","        # CABA: reglas t√≠picas\n","        if nombre_col == \"provincia_nombre\":\n","            d.loc[d[id_col].isna() \u0026 (d[nombre_col] == \"CIUDAD AUTONOMA DE BUENOS AIRES\"), id_col] = 2\n","        if nombre_col == \"departamento_nombre\":\n","            if \"provincia_nombre\" in d.columns:\n","                m = d.loc[d[id_col].isna() \u0026 (d[\"provincia_nombre\"]==\"CIUDAD AUTONOMA DE BUENOS AIRES\"), nombre_col].str.extract(r'COMUNA\\s*(\\d+)')\n","                idxs = m.dropna().index\n","                d.loc[idxs, id_col] = 2000 + m.loc[idxs, 0].astype(int)\n","\n","        # Para el resto, generar IDs deterministas por hash corto\n","        still = d[id_col].isna() \u0026 d[nombre_col].notna()\n","        if still.any():\n","            base = d.loc[still, nombre_col].astype(str)\n","            if adicionales_keys and all(k in d.columns for k in adicionales_keys):\n","                extra = d.loc[still, adicionales_keys].astype(str).agg(\"|\".join, axis=1)\n","                key = (base + \"|\" + extra)\n","            else:\n","                key = base\n","            d.loc[still, id_col] = key.map(lambda s: abs(hash(s)) % 10_000_000 + 1_000_000)\n","            d[id_col] = pd.to_numeric(d[id_col], errors=\"coerce\").astype(\"Int64\")\n","    return d\n","\n","# Provincia\n","if \"provincia_nombre\" in df.columns and \"provincia_id\" in df.columns:\n","    df = completar_id_por_modo(df, \"provincia_nombre\", \"provincia_id\")\n","elif \"provincia_nombre\" in df.columns:\n","    df[\"provincia_id\"] = pd.Series([pd.NA]*len(df), dtype=\"Int64\")\n","    df = completar_id_por_modo(df, \"provincia_nombre\", \"provincia_id\")\n","\n","# Departamento (usa provincia como llave adicional)\n","if \"departamento_nombre\" in df.columns and \"departamento_id\" in df.columns:\n","    df = completar_id_por_modo(df, \"departamento_nombre\", \"departamento_id\", adicionales_keys=[\"provincia_nombre\"])\n","elif \"departamento_nombre\" in df.columns:\n","    df[\"departamento_id\"] = pd.Series([pd.NA]*len(df), dtype=\"Int64\")\n","    df = completar_id_por_modo(df, \"departamento_nombre\", \"departamento_id\", adicionales_keys=[\"provincia_nombre\"])\n","\n","# -------- 6) Fecha semanal (si a√∫n no existe) --------\n","from datetime import date\n","def iso_week_start_safe(year, week):\n","    try: return pd.to_datetime(date.fromisocalendar(int(year), int(week), 1))\n","    except: return pd.NaT\n","\n","if \"fecha_semana\" not in df.columns:\n","    if {\"anio\",\"semana_epidemiologica\"}.issubset(df.columns):\n","        df[\"fecha_semana\"] = df.apply(lambda r: iso_week_start_safe(r[\"anio\"], r[\"semana_epidemiologica\"]), axis=1)\n","    elif \"fecha\" in df.columns:\n","        df[\"fecha_semana\"] = pd.to_datetime(df[\"fecha\"], errors=\"coerce\")\n","    else:\n","        df[\"fecha_semana\"] = pd.NaT\n","df = df[df[\"fecha_semana\"].notna()].copy()\n","\n","# -------- 7) Promedio semanal de clima (precipitaci√≥n, temperatura, humedad) --------\n","climate_cols = [c for c in df.columns if any(k in c.lower() for k in [\"temp\",\"hum\",\"prec\"]) and is_numeric_dtype(df[c])]\n","if not climate_cols:\n","    print(\"‚ö†Ô∏è No se detectaron columnas clim√°ticas num√©ricas.\")\n","else:\n","    dias = [\"_L\",\"_M\",\"_X\",\"_J\",\"_V\",\"_S\",\"_D\"]\n","    def promedio_intrafila(df, base):\n","        cols = [c for c in df.columns if c.lower().startswith(base) and any(c.endswith(d) for d in dias)]\n","        if cols:\n","            return df[cols].mean(axis=1)\n","        return None\n","\n","    for base in [\"temp\", \"hum\", \"prec\"]:\n","        col_prom = f\"{base}_sem_prom\"\n","        val = promedio_intrafila(df, base)\n","        if isinstance(val, pd.Series):\n","            df[col_prom] = val\n","\n","    for base in [\"temp\",\"hum\",\"prec\"]:\n","        if f\"{base}_sem_prom\" not in df.columns:\n","            cand = [c for c in climate_cols if c.lower().startswith(base)]\n","            if cand:\n","                df[f\"{base}_row\"] = df[cand].mean(axis=1)\n","\n","    group_keys = [k for k in [\"fecha_semana\",\"provincia_nombre\",\"departamento_nombre\"] if k in df.columns]\n","    if not group_keys:\n","        group_keys = [\"fecha_semana\"]\n","\n","    agg_dict = {case_col: \"sum\"}\n","    for base in [\"temp\",\"hum\",\"prec\"]:\n","        if f\"{base}_sem_prom\" in df.columns:\n","            agg_dict[f\"{base}_sem_prom\"] = \"mean\"\n","        if f\"{base}_row\" in df.columns:\n","            agg_dict[f\"{base}_row\"] = \"mean\"\n","\n","    clima_sem = df.groupby(group_keys).agg(agg_dict).reset_index()\n","\n","    clima_sem = clima_sem.rename(columns={\n","        \"temp_sem_prom\": \"temp_semana\",\n","        \"hum_sem_prom\": \"hum_semana\",\n","        \"prec_sem_prom\": \"prec_semana\",\n","        \"temp_row\": \"temp_semana\",\n","        \"hum_row\": \"hum_semana\",\n","        \"prec_row\": \"prec_semana\",\n","    })\n","\n","    clima_cols_finales = [c for c in [\"temp_semana\",\"hum_semana\",\"prec_semana\"] if c in clima_sem.columns]\n","    if clima_cols_finales:\n","        clima_sem = (clima_sem\n","                     .groupby(group_keys, as_index=False)\n","                     .agg({case_col:\"sum\", **{c:\"mean\" for c in clima_cols_finales}}))\n","\n","    print(\"clima_sem (muestra):\")\n","    display(clima_sem.head())\n","\n","\n","# -------- 7.1) Columnas mes/a√±o desde 'fecha' y filtro enero‚Äìjunio --------\n","# Asegurar que 'fecha' exista y sea datetime\n","if \"fecha\" in df.columns:\n","    df[\"fecha\"] = pd.to_datetime(df[\"fecha\"], errors=\"coerce\")\n","elif \"fecha_semana\" in df.columns:\n","    df[\"fecha\"] = pd.to_datetime(df[\"fecha_semana\"], errors=\"coerce\")\n","else:\n","    raise ValueError(\"No se encontr√≥ 'fecha' ni 'fecha_semana' para derivar mes/a√±o.\")\n","\n","# Crear columnas nuevas desde 'fecha'\n","df[\"mes\"] = df[\"fecha\"].dt.month.astype(\"Int64\")\n","df[\"anio_fecha\"] = df[\"fecha\"].dt.year.astype(\"Int64\")\n","\n","# Filtrar meses de enero (1) a junio (6) inclusive\n","df = df[df[\"mes\"].between(1, 6)].copy()\n","\n","# (opcional) si tambi√©n quer√©s filtrar la tabla agregada 'clima_sem' cuando la generes,\n","# asegurate de que 'clima_sem' tenga una columna de fecha (o derivala igual que arriba)\n","# y aplic√° el mismo filtro. Por ejemplo, si us√°s 'fecha_semana' en clima_sem:\n","# if \"clima_sem\" in locals():\n","#     if \"fecha_semana\" in clima_sem.columns:\n","#         clima_sem[\"mes\"] = pd.to_datetime(clima_sem[\"fecha_semana\"]).dt.month\n","#         clima_sem = clima_sem[clima_sem[\"mes\"].between(1,6)].copy()\n","\n","\n","# -------- 9) Reporte final de nulos --------\n","print(\"\\n--- VERIFICACI√ìN DE NULOS (post-procesamiento) ---\")\n","display(df.isna().sum().sort_values(ascending=False).to_frame(\"n_nulos\"))\n","print(\"Filas x Columnas:\", df.shape)\n","\n","\n","# --- Diagn√≥stico: revisar cu√°ntos quedaron como DESCONOCIDO ---\n","n_total = len(df)\n","n_descon = (df[\"grupo_edad_desc_std\"] == \"DESCONOCIDO\").sum()\n","porc = (n_descon / n_total * 100) if n_total \u003e 0 else 0\n","\n","print(f\"Registros con grupo_edad_desc_std = 'DESCONOCIDO': {n_descon:,} de {n_total:,} ({porc:.2f}%)\")\n","\n","# Ver ejemplos de los valores originales que generaron 'DESCONOCIDO'\n","display(\n","    df.loc[df[\"grupo_edad_desc_std\"] == \"DESCONOCIDO\", [\"grupo_edad_desc\"]]\n","      .value_counts()\n","      .reset_index(name=\"frecuencia\")\n","      .head(20)\n",")\n","\n","df_nulos = df[df[\"grupo_edad_desc_std\"].isna()]\n","display(df_nulos)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9eMOV80I9USd"},"outputs":[],"source":["# =========================\n","# Clasificaci√≥n clim√°tica por provincia -\u003e df[\"clima_region\"]\n","# Cobertura 100% (sin MIXTO/OTROS) + aviso de provincias no mapeadas\n","# =========================\n","\n","def fix_prov_name(p):\n","    if pd.isna(p):\n","        return p\n","    p = str(p).strip().upper()\n","    if p in {\"CABA\",\"CIUDAD AUTONOMA BUENOS AIRES\",\"CAPITAL FEDERAL\",\"CIUDAD AUTONOMA DE BUENOS AIRES\"}:\n","        return \"CABA\"\n","    # tildes b√°sicas\n","    repl = str.maketrans(\"√Å√â√ç√ì√ö√ë\", \"AEIOUN\")\n","    return p.translate(repl)\n","\n","# Normaliz√° provincia\n","if \"provincia_nombre\" in df.columns:\n","    df[\"provincia_nombre\"] = df[\"provincia_nombre\"].apply(fix_prov_name)\n","else:\n","    raise ValueError(\"Falta la columna 'provincia_nombre' en df.\")\n","\n","# --- Mapeo exhaustivo por provincia (24 jurisdicciones) ---\n","# Criterio:\n","#   - TEMPLADO: Buenos Aires, CABA, Entre R√≠os, Santa Fe, C√≥rdoba, La Pampa\n","#   - SUBTROPICAL: Misiones, Chaco, Corrientes, Formosa\n","#   - ARIDO/SEMIARIDO: Catamarca, La Rioja, San Juan, San Luis, Santiago del Estero, Santa Cruz, Tierra del Fuego...\n","#   - FRIO/MONTANA: Mendoza, Neuqu√©n, R√≠o Negro, Chubut, Jujuy, Salta\n","PROVINCIA_A_CLIMA = {\n","    # TEMPLADO\n","    \"BUENOS AIRES\": \"TEMPLADO\",\n","    \"CIUDAD AUTONOMA DE BUENOS AIRES\": \"TEMPLADO\",\n","    \"CABA\": \"TEMPLADO\",\n","    \"ENTRE RIOS\": \"TEMPLADO\",\n","    \"SANTA FE\": \"TEMPLADO\",\n","    \"CORDOBA\": \"TEMPLADO\",\n","    \"LA PAMPA\": \"TEMPLADO\",\n","\n","    # SUBTROPICAL (NEA)\n","    \"MISIONES\": \"SUBTROPICAL\",\n","    \"CHACO\": \"SUBTROPICAL\",\n","    \"CORRIENTES\": \"SUBTROPICAL\",\n","    \"FORMOSA\": \"SUBTROPICAL\",\n","    \"TUCUMAN\": \"SUBTROPICAL\",\n","\n","    # ARIDO/SEMIARIDO (Puna/Sierras/Patagonia extraandina)\n","    \"CATAMARCA\": \"ARIDO/SEMIARIDO\",\n","    \"LA RIOJA\": \"ARIDO/SEMIARIDO\",\n","    \"SAN JUAN\": \"ARIDO/SEMIARIDO\",\n","    \"SAN LUIS\": \"ARIDO/SEMIARIDO\",\n","    \"SANTIAGO DEL ESTERO\": \"ARIDO/SEMIARIDO\",\n","    \"SANTA CRUZ\": \"ARIDO/SEMIARIDO\",\n","    \"TIERRA DEL FUEGO, ANTARTIDA E ISLAS DEL ATLANTICO SUR\": \"ARIDO/SEMIARIDO\",\n","    \"TIERRA DEL FUEGO\": \"ARIDO/SEMIARIDO\",\n","\n","    # FRIO/MONTANA (Cordillera/NOA andino + Norpatagonia andina)\n","    \"MENDOZA\": \"FRIO/MONTANA\",\n","    \"NEUQUEN\": \"FRIO/MONTANA\",\n","    \"RIO NEGRO\": \"FRIO/MONTANA\",\n","    \"CHUBUT\": \"FRIO/MONTANA\",\n","    \"JUJUY\": \"FRIO/MONTANA\",\n","    \"SALTA\": \"FRIO/MONTANA\",\n","}\n","\n","# Asignaci√≥n primaria por mapeo\n","df[\"clima_region\"] = df[\"provincia_nombre\"].map(PROVINCIA_A_CLIMA)\n","\n","# Detectar provincias no cubiertas por el mapeo\n","provincias_en_df = set(df[\"provincia_nombre\"].dropna().unique())\n","provincias_mapeadas = set(PROVINCIA_A_CLIMA.keys())\n","faltantes = sorted(p for p in provincias_en_df if p not in provincias_mapeadas)\n","\n","if faltantes:\n","    print(\"‚ö†Ô∏è Provincias no reconocidas en el mapeo y asignadas por DEFAULT a 'TEMPLADO':\")\n","    for p in faltantes:\n","        print(\"  -\", p)\n","    # Fallback operativo para no cortar el an√°lisis\n","    df.loc[df[\"provincia_nombre\"].isin(faltantes), \"clima_region\"] = \"TEMPLADO\"\n","\n","# Chequeo final: garantizar sin nulos\n","if df[\"clima_region\"].isna().any():\n","    # Si a√∫n quedara alg√∫n nulo (p.ej. provincia NaN), forzar a TEMPLADO\n","    df[\"clima_region\"] = df[\"clima_region\"].fillna(\"TEMPLADO\")\n","\n","\n","\n","\n","df_grouped = df.groupby(\n","    [\"provincia_nombre\", \"departamento_nombre\", \"anio\", \"semana_epidemiologica\",\"fecha_semana\",\"temp_sem_prom\",\"hum_sem_prom\",\"prec_sem_prom\",\"clima_region\",\"densidad\",\"grupo_edad_id\",\"grupo_edad_desc\",\"grupo_edad_desc_std\" ]\n",")[\"cantidad_casos\"].sum().reset_index()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"output_embedded_package_id":"1Ti2K743e93lHVDVkxSgxVclEJtcGrNmK"},"id":"O0ET68_G9mGu","outputId":"9e71dc18-bbff-4f6f-92bf-312dceccc107"},"outputs":[],"source":["import altair as alt\n","import pandas as pd\n","import numpy as np\n","import uuid\n","\n","alt.renderers.enable('default')\n","alt.data_transformers.enable('default', max_rows=None)\n","\n","# ==== datos (ajusta si hace falta) ====\n","reg_col = \"clima_region\"\n","features = [\"densidad\", \"temp_sem_prom\", \"hum_sem_prom\", \"prec_sem_prom\"]\n","use_cols = [\"provincia_nombre\",\"departamento_nombre\",\"fecha_semana\", reg_col] + features\n","dfv = (df_grouped[use_cols]\n","       .dropna(subset=[reg_col] + features)\n","       .rename(columns={reg_col: \"region\"})\n","       .copy())\n","dfv[\"fecha_semana\"] = pd.to_datetime(dfv[\"fecha_semana\"], errors=\"coerce\")\n","meses_map = {1:\"Enero\",2:\"Febrero\",3:\"Marzo\",4:\"Abril\",5:\"Mayo\",6:\"Junio\",\n","             7:\"Julio\",8:\"Agosto\",9:\"Septiembre\",10:\"Octubre\",11:\"Noviembre\",12:\"Diciembre\"}\n","dfv[\"mes_desc\"] = dfv[\"fecha_semana\"].dt.month.map(meses_map)\n","\n","# ==== opciones de dropdown ====\n","regiones = sorted(dfv[\"region\"].dropna().unique().tolist())\n","meses_desc = [meses_map[m] for m in sorted(dfv[\"fecha_semana\"].dt.month.dropna().unique())]\n","\n","# ==== par√°metros (NO son selections, no generan *_tuple) ====\n","SUF = str(uuid.uuid4())[:6]  # por si quer√©s evitar colisiones entre celdas\n","param_region = alt.param(name=f\"region_sel_{SUF}\",\n","                         bind=alt.binding_select(options=[\"(todas)\"] + regiones, name=\"Regi√≥n: \"))\n","param_mes    = alt.param(name=f\"mes_sel_{SUF}\",\n","                         bind=alt.binding_select(options=[\"(todos)\"] + meses_desc, name=\"Mes: \"))\n","\n","# ==== filtros usando los params (dejan pasar todo si no se elige nada o se elige '(todas)/(todos)') ====\n","filtro_region = f\"\"\"!isValid({param_region.name}) || {param_region.name}==\"\" ||\n","                   {param_region.name}==\"(todas)\" || datum.region=={param_region.name}\"\"\"\n","filtro_mes    = f\"\"\"!isValid({param_mes.name})    || {param_mes.name}==\"\" ||\n","                   {param_mes.name}==\"(todos)\"   || datum.mes_desc=={param_mes.name}\"\"\"\n","\n","# ======= EJEMPLO DE DOS GR√ÅFICOS QUE COMPARTEN LOS MISMOS PARAMS =======\n","\n","# 1) Heatmap ‚Äúhuella‚Äù (z-scores por regi√≥n y variable)\n","mean_by_reg_feat = (dfv.melt(id_vars=[\"region\"], value_vars=features,\n","                             var_name=\"variable\", value_name=\"valor\")\n","                      .groupby([\"region\",\"variable\"], as_index=False)[\"valor\"].mean())\n","z_df = []\n","for v in features:\n","    sub = mean_by_reg_feat[mean_by_reg_feat[\"variable\"] == v].copy()\n","    mu, sd = sub[\"valor\"].mean(), sub[\"valor\"].std(ddof=0)\n","    sub[\"z\"] = (sub[\"valor\"] - mu) / (sd if sd \u003e 0 else 1.0)\n","    z_df.append(sub)\n","z_df = pd.concat(z_df, ignore_index=True)\n","order_vars = (z_df.groupby(\"variable\")[\"z\"].apply(lambda s: s.max()-s.min())\n","                  .sort_values(ascending=False).index.tolist())\n","\n","heat = (alt.Chart(z_df)\n","          .transform_filter(filtro_region)  # usa el param, pero NO lo agrega ac√°\n","          .mark_rect()\n","          .encode(\n","              x=alt.X(\"variable:N\", title=\"Variable\", sort=order_vars),\n","              y=alt.Y(\"region:N\",   title=\"Regi√≥n\"),\n","              color=alt.Color(\"z:Q\", title=\"Z-score\",\n","                              scale=alt.Scale(scheme=\"blueorange\", domainMid=0)),\n","              tooltip=[\"region:N\",\"variable:N\",alt.Tooltip(\"valor:Q\",format=\".2f\"),alt.Tooltip(\"z:Q\",format=\".2f\")]\n","          )\n","          .properties(title=\"Huella por regi√≥n (z-score por variable)\", width=420, height=160))\n","\n","# 2) Boxplots facetados con filtros por regi√≥n y mes (mismo param)\n","long_df = dfv.melt(id_vars=[\"region\",\"provincia_nombre\",\"departamento_nombre\",\"mes_desc\"],\n","                   value_vars=features, var_name=\"variable\", value_name=\"valor\").dropna(subset=[\"valor\"])\n","box = (alt.Chart(long_df)\n","         .transform_filter(filtro_region)\n","         .transform_filter(filtro_mes)\n","         .mark_boxplot(outliers=True)\n","         .encode(\n","             y=alt.Y(\"region:N\", title=\"Regi√≥n\", sort=regiones),\n","             x=alt.X(\"valor:Q\",  title=\"Valor\"),\n","             color=alt.Color(\"region:N\", legend=None),\n","             tooltip=[\"region:N\",\"variable:N\",\"valor:Q\"]\n","         )\n","         .properties(width=250, height=120))\n","box_grid = (box.facet(column=alt.Column(\"variable:N\", title=None, sort=order_vars))\n","                 .resolve_scale(x=\"independent\")\n","                 .properties(title=\"Distribuci√≥n de variables por regi√≥n (filtr√° opcionalmente)\"))\n","\n","# üëâ Agreg√° los params SOLO en el contenedor\n","layout = (heat | box_grid).add_params(param_region, param_mes)\n","layout\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"XPabdS2gCPFl"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMY3SKzymGZmOStg9Gz0P0r","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}